{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "1. Find a word that appears no more than 20 times in all of Pausanias, and calculate it's R<sub>2</sub> for Pausanias' text when divided by book.\n",
    "2. Find the standard deviation of the relative frequencies of forms of ποιέω in the books of Pausanias.\n",
    "3. Calculate the deviation of proportions for a word of your choosing in the books of Pausanias.\n",
    "4. Calculate the TTR for each book of Pausanias, and for Pausanias as a whole.\n",
    "5. Calculate the MATTR of Pausanias using a sliding window of 5000 tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MyCapytain.resources.texts.local.capitains.cts import CapitainsCtsText\n",
    "\n",
    "with open(\"../tei/tlg0525.tlg001.perseus-eng2.xml\") as f:\n",
    "    text = CapitainsCtsText(urn=\"urn:cts:greekLit:tlg0525.tlg001.perseus-eng2\", resource=f)\n",
    "\n",
    "from lxml import etree\n",
    "from MyCapytain.common.constants import Mimetypes\n",
    "\n",
    "urns = []\n",
    "raw_xmls = []\n",
    "unannotated_strings = []\n",
    "\n",
    "for ref in text.getReffs(level=len(text.citation)):\n",
    "    urn = f\"{text.urn}:{ref}\"\n",
    "    node = text.getTextualNode(ref)\n",
    "    raw_xml = node.export(Mimetypes.XML.TEI)\n",
    "    tree = node.export(Mimetypes.PYTHON.ETREE)\n",
    "    s = etree.tostring(tree, encoding=\"unicode\", method=\"text\")\n",
    "\n",
    "    urns.append(urn)\n",
    "    raw_xmls.append(raw_xml)\n",
    "    unannotated_strings.append(s)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "d = {\n",
    "    \"urn\": pd.Series(urns, dtype=\"string\"),\n",
    "    \"raw_xml\": raw_xmls,\n",
    "    \"unannotated_strings\": pd.Series(unannotated_strings, dtype=\"string\")\n",
    "}\n",
    "pausanias_df = pd.DataFrame(d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "absolute frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will take a while\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\"])\n",
    "\n",
    "raw_texts = [t for t in pausanias_df['unannotated_strings']]\n",
    "annotated_texts = nlp.pipe(raw_texts, batch_size=100)\n",
    "\n",
    "pausanias_df['nlp_docs'] = list(annotated_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "definite_article = [t for t in pausanias_df['nlp_docs'].explode() if t.lemma_ == \"treatment\"]\n",
    "\n",
    "len(definite_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "relative frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.919526\n"
     ]
    }
   ],
   "source": [
    "n_definite_article = len(definite_article)\n",
    "n_tokens = len([t for t in pausanias_df['nlp_docs'].explode()])\n",
    "basis = 1_000_000\n",
    "\n",
    "rf_definite_article_in_pausanias = (n_definite_article * n_tokens) / basis\n",
    "\n",
    "print(rf_definite_article_in_pausanias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['treatment',\n",
       " 'naval',\n",
       " 'King',\n",
       " 'powerful',\n",
       " 'guardian',\n",
       " 'Cyprus',\n",
       " 'board',\n",
       " 'Pergamus',\n",
       " 'invent',\n",
       " 'Erechtheus',\n",
       " 'alliance',\n",
       " 'task',\n",
       " 'really',\n",
       " 'base',\n",
       " 'master',\n",
       " 'ascend',\n",
       " 'deep',\n",
       " 'vision',\n",
       " 'plague',\n",
       " 'valor',\n",
       " 'outrage',\n",
       " 'elect',\n",
       " 'labour',\n",
       " 'Cronus',\n",
       " 'dog',\n",
       " 'unite',\n",
       " 'voyage',\n",
       " 'Polygnotus',\n",
       " 'Cypselus',\n",
       " 'past',\n",
       " 'Callisto',\n",
       " 'subsequently',\n",
       " 'Acarnanians',\n",
       " 'oil',\n",
       " 'adjoin',\n",
       " 'below',\n",
       " 'winner',\n",
       " 'anything',\n",
       " 'Tanagra',\n",
       " 'pair',\n",
       " 'knee',\n",
       " 'Neleus',\n",
       " 'grant',\n",
       " 'enjoy',\n",
       " 'Polydorus',\n",
       " 'pray',\n",
       " 'twice',\n",
       " 'decide',\n",
       " 'Hippocoon',\n",
       " 'Polyneices',\n",
       " 'Clymenus',\n",
       " 'meeting',\n",
       " 'speech',\n",
       " 'Iphitus',\n",
       " 'clearly',\n",
       " 'Lycaeus',\n",
       " 'seventy',\n",
       " 'Phigalians',\n",
       " 'Aleus',\n",
       " 'Mistress']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = Counter([t.lemma_ for t in pausanias_df['nlp_docs'].explode() if t.is_alpha])\n",
    "hapaxes = [h for (h, i) in counts.items() if i == 19]\n",
    "\n",
    "hapaxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Treatment\" is chosen to be the word that occurs less than 20 times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation of R2 of \"treatment\" among Pausanias' books below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../tei/tlg0525.tlg002.perseus-eng2.xml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mMyCapytain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresources\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtexts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlocal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcapitains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CapitainsCtsText\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../tei/tlg0525.tlg002.perseus-eng2.xml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m     text \u001b[38;5;241m=\u001b[39m CapitainsCtsText(urn\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murn:cts:greekLit:tlg0525.tlg002.perseus-eng2\u001b[39m\u001b[38;5;124m\"\u001b[39m, resource\u001b[38;5;241m=\u001b[39mf)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlxml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m etree\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../tei/tlg0525.tlg002.perseus-eng2.xml'"
     ]
    }
   ],
   "source": [
    "from MyCapytain.resources.texts.local.capitains.cts import CapitainsCtsText\n",
    "\n",
    "with open(\"../tei/tlg0525.tlg002.perseus-eng2.xml\") as f:\n",
    "    text = CapitainsCtsText(urn=\"urn:cts:greekLit:tlg0525.tlg002.perseus-eng2\", resource=f)\n",
    "\n",
    "from lxml import etree\n",
    "from MyCapytain.common.constants import Mimetypes\n",
    "\n",
    "urns = []\n",
    "raw_xmls = []\n",
    "unannotated_strings = []\n",
    "\n",
    "for ref in text.getReffs(level=len(text.citation)):\n",
    "    urn = f\"{text.urn}:{ref}\"\n",
    "    node = text.getTextualNode(ref)\n",
    "    raw_xml = node.export(Mimetypes.XML.TEI)\n",
    "    tree = node.export(Mimetypes.PYTHON.ETREE)\n",
    "    s = etree.tostring(tree, encoding=\"unicode\", method=\"text\")\n",
    "\n",
    "    urns.append(urn)\n",
    "    raw_xmls.append(raw_xml)\n",
    "    unannotated_strings.append(s)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "d = {\n",
    "    \"urn\": pd.Series(urns, dtype=\"string\"),\n",
    "    \"raw_xml\": raw_xmls,\n",
    "    \"unannotated_strings\": pd.Series(unannotated_strings, dtype=\"string\")\n",
    "}\n",
    "pausanias_df = pd.DataFrame(d)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
